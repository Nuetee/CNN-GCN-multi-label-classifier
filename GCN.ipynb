{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.models import Sequential, Model\n",
    "# from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add, Input, Flatten\n",
    "\n",
    "# import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.style as style\n",
    "# import seaborn as sns\n",
    "# import cv2\n",
    "# from utils import *\n",
    "\n",
    "# BATCH_SIZE = 256  # Big enough to measure an F1-score\n",
    "# # Adapt preprocessing and prefetching dynamically\n",
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# SHUFFLE_BUFFER_SIZE = 8192\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = './database_test'\n",
    "\n",
    "file_list = os.listdir(dir_path)\n",
    "ID = []\n",
    "Labels = []\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_name = file_name[0: len(file_name) - 4]\n",
    "    label_list = file_name.split('+')\n",
    "    if (label_list[0] == ''):\n",
    "        continue\n",
    "    ID.append(label_list[0])\n",
    "    del label_list[0]\n",
    "\n",
    "    valid_label_list = []\n",
    "    for label in label_list:\n",
    "        label = label.lower()\n",
    "        labels = label.split(', ')\n",
    "        valid_label_list.extend(labels)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            valid_label_list.remove('')\n",
    "        except ValueError:\n",
    "            break\n",
    "\n",
    "    Labels.append(valid_label_list)\n",
    "\n",
    "artworks = pd.DataFrame({\"ID\": ID, \"Labels\": Labels, \"File\": file_list})\n",
    "artworks.dropna()\n",
    "\n",
    "# Get label frequencies in descending order\n",
    "label_freq = artworks['Labels'].apply(\n",
    "    lambda s: [x for x in s]).explode().value_counts().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used labels: 58\n",
      "Number of ignored labels: 97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Labels</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[allegorical painting, mannerism (late renaiss...</td>\n",
       "      <td>10+allegorical painting+Mannerism (Late Renais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>[still life, naïve art (primitivism), oil]</td>\n",
       "      <td>100+still life+Naïve Art (Primitivism)+oil, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>[religious painting, baroque, tenebrism, oil, ...</td>\n",
       "      <td>1000+religious painting+Baroque, Tenebrism+oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>[religious painting, baroque, tenebrism, oil, ...</td>\n",
       "      <td>1001+religious painting+Baroque, Tenebrism+oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002</td>\n",
       "      <td>[religious painting, baroque, tenebrism, oil, ...</td>\n",
       "      <td>1002+religious painting+Baroque, Tenebrism+oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1003</td>\n",
       "      <td>[religious painting, baroque, tenebrism, oil, ...</td>\n",
       "      <td>1003+religious painting+Baroque, Tenebrism+oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1004</td>\n",
       "      <td>[religious painting, baroque, tenebrism, oil, ...</td>\n",
       "      <td>1004+religious painting+Baroque, Tenebrism+oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1005</td>\n",
       "      <td>[mythological painting, baroque, tenebrism, oi...</td>\n",
       "      <td>1005+mythological painting+Baroque, Tenebrism+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1006</td>\n",
       "      <td>[still life, baroque, tenebrism, oil, canvas]</td>\n",
       "      <td>1006+still life+Baroque, Tenebrism+oil, canvas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1007</td>\n",
       "      <td>[religious painting, baroque, tenebrism, oil, ...</td>\n",
       "      <td>1007+religious painting+Baroque, Tenebrism+oil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                             Labels  \\\n",
       "0    10  [allegorical painting, mannerism (late renaiss...   \n",
       "1   100         [still life, naïve art (primitivism), oil]   \n",
       "2  1000  [religious painting, baroque, tenebrism, oil, ...   \n",
       "3  1001  [religious painting, baroque, tenebrism, oil, ...   \n",
       "4  1002  [religious painting, baroque, tenebrism, oil, ...   \n",
       "5  1003  [religious painting, baroque, tenebrism, oil, ...   \n",
       "6  1004  [religious painting, baroque, tenebrism, oil, ...   \n",
       "7  1005  [mythological painting, baroque, tenebrism, oi...   \n",
       "8  1006      [still life, baroque, tenebrism, oil, canvas]   \n",
       "9  1007  [religious painting, baroque, tenebrism, oil, ...   \n",
       "\n",
       "                                                File  \n",
       "0  10+allegorical painting+Mannerism (Late Renais...  \n",
       "1  100+still life+Naïve Art (Primitivism)+oil, co...  \n",
       "2  1000+religious painting+Baroque, Tenebrism+oil...  \n",
       "3  1001+religious painting+Baroque, Tenebrism+oil...  \n",
       "4  1002+religious painting+Baroque, Tenebrism+oil...  \n",
       "5  1003+religious painting+Baroque, Tenebrism+oil...  \n",
       "6  1004+religious painting+Baroque, Tenebrism+oil...  \n",
       "7  1005+mythological painting+Baroque, Tenebrism+...  \n",
       "8  1006+still life+Baroque, Tenebrism+oil, canvas...  \n",
       "9  1007+religious painting+Baroque, Tenebrism+oil...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of rare labels\n",
    "# rare = list(label_freq[label_freq < 50].index)\n",
    "rare = list(label_freq[label_freq < 25].index)\n",
    "print(\"Number of used labels:\", len(label_freq) - len(rare))\n",
    "print(\"Number of ignored labels:\", len(rare))\n",
    "label_number = len(label_freq) - len(rare)\n",
    "\n",
    "artworks['Labels'] = artworks['Labels'].apply(\n",
    "    lambda s: [x for x in s if x not in rare])\n",
    "artworks['Labels'] = artworks['Labels'].apply(\n",
    "    lambda s: s if len(s) != 0 else np.nan)\n",
    "\n",
    "artworks.dropna(inplace=True)\n",
    "artworks.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./database_test\\\\2105+sculpture+Baroque+.jpg',\n",
       " './database_test\\\\1231+portrait+Pop Art+oil, canvas.jpg',\n",
       " './database_test\\\\1972+portrait+Neoclassicism+pastel.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 파일 경로 및 label 집합으로 train data와 valid data parsing\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    artworks['File'], artworks['Labels'], test_size=0.1, random_state=23)\n",
    "\n",
    "X_train = [os.path.join('./database_test', str(f)) for f in X_train]\n",
    "X_val = [os.path.join('./database_test', str(f)) for f in X_val]\n",
    "X_train[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiLabelBinarizer로 다중 label 이진화\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(artworks['Labels'])\n",
    "\n",
    "# Loop over all labels and show them\n",
    "N_LABELS = len(mlb.classes_)\n",
    "\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "mlb.fit(y_val)\n",
    "y_val_bin = mlb.transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for _ 는 변수없이 반복문 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        class1                class2  correlation  class1_idx  class2_idx\n",
      "0     abstract              abstract          205           0           0\n",
      "1     abstract          abstract art          135           0           1\n",
      "2     abstract  allegorical painting            0           0           2\n",
      "3     abstract  art nouveau (modern)            0           0           3\n",
      "4     abstract               baroque            0           0           4\n",
      "...        ...                   ...          ...         ...         ...\n",
      "3131      wood            surrealism            0          55          51\n",
      "3132      wood               tempera           22          55          52\n",
      "3133      wood             tenebrism            1          55          53\n",
      "3134      wood            watercolor            0          55          54\n",
      "3135      wood                  wood           76          55          55\n",
      "\n",
      "[3136 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "node_train_df = pd.DataFrame(columns=['class'])\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "  node_train_df.loc[i] = label\n",
    "\n",
    "node_train_df.reset_index()\n",
    "\n",
    "class_combinations = list(product(mlb.classes_, repeat=2))\n",
    "edge_train_df = pd.DataFrame(columns=['class1', 'class2', 'correlation'])\n",
    "\n",
    "# edge_df 초기화\n",
    "for (i, class_combination) in enumerate(class_combinations):\n",
    "  edge_train_df.loc[i] = [class_combination[0], class_combination[1], 0]\n",
    "\n",
    "edge_train_df.reset_index()\n",
    "\n",
    "# 각 edge_df 값 주입.\n",
    "for label in Labels:\n",
    "  label_combinations = list(product(label, repeat=2))\n",
    "  for label_combination in label_combinations:\n",
    "    condition = (edge_train_df['class1'] == label_combination[0]) & (\n",
    "        edge_train_df['class2'] == label_combination[1])\n",
    "\n",
    "    if (edge_train_df[condition].index.tolist()):\n",
    "      index = edge_train_df[condition].index.tolist()[0]\n",
    "      edge_train_df.loc[index, 'correlation'] += 1\n",
    "     \n",
    "merge_train_df = node_train_df.reset_index().set_index(\n",
    "    'class').rename(columns={'index': 'class1_idx'})\n",
    "edge_train_df = pd.merge(\n",
    "    edge_train_df, merge_train_df['class1_idx'], how='left', left_on='class1', right_index=True)\n",
    "merge_train_df = merge_train_df.rename(columns={'class1_idx': 'class2_idx'})\n",
    "edge_train_df = pd.merge(\n",
    "    edge_train_df, merge_train_df['class2_idx'], how='left', left_on='class2', right_index=True)\n",
    "\n",
    "print(edge_train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorDataset element_spec=GraphTensorSpec({'context': ContextSpec({'features': {}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'node_sets': {'Label': NodeSetSpec({'features': {'index': TensorSpec(shape=(42, 1), dtype=tf.int32, name=None)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None)}, 'edge_sets': {'Correlation': EdgeSetSpec({'features': {'connection-strength': TensorSpec(shape=(1764, 1), dtype=tf.float64, name=None)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(1764,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(1764,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'Label', '#index.1': 'Label'})}, TensorShape([]), tf.int32, None)}}, TensorShape([]), tf.int32, None)>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_gnn as tfgnn\n",
    "\n",
    "def create_graph_tensor(node_df, edge_df):\n",
    "    graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "        node_sets={\n",
    "            \"Label\": tfgnn.NodeSet.from_fields(\n",
    "                sizes=[len(node_df)],\n",
    "                features={\n",
    "                    'index': np.array(node_df.index, dtype='int32').reshape(len(node_df), 1)\n",
    "                    # 'feature': tf.constant(y_train_bin)\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        edge_sets={\n",
    "            \"Correlation\": tfgnn.EdgeSet.from_fields(\n",
    "                sizes=[len(edge_df)],\n",
    "                features={\n",
    "                    'connection-strength': np.array(edge_df['correlation'], dtype='float').reshape(len(edge_df), 1)\n",
    "                },\n",
    "                adjacency=tfgnn.Adjacency.from_indices(\n",
    "                    source=(\"Label\", np.array(\n",
    "                        edge_df['class1_idx'], dtype='int32')),\n",
    "                    target=(\"Label\", np.array(\n",
    "                        edge_df['class2_idx'], dtype='int32'))\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    return graph_tensor\n",
    "\n",
    "train_tensor = create_graph_tensor(node_train_df, edge_train_df)\n",
    "dataset = tf.data.Dataset.from_tensors(train_tensor)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(GraphTensorSpec({'context': ContextSpec({'features': {}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'node_sets': {'Label': NodeSetSpec({'features': {'index': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None)}, 'edge_sets': {'Correlation': EdgeSetSpec({'features': {'connection-strength': TensorSpec(shape=(None, 1), dtype=tf.float64, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'Label', '#index.1': 'Label'})}, TensorShape([]), tf.int32, None)}}, TensorShape([]), tf.int32, None), TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))>\n",
      "<MapDataset element_spec=GraphTensorSpec({'context': ContextSpec({'features': {}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'node_sets': {'Label': NodeSetSpec({'features': {'index': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None)}, 'edge_sets': {'Correlation': EdgeSetSpec({'features': {'connection-strength': TensorSpec(shape=(None, 1), dtype=tf.float64, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'Label', '#index.1': 'Label'})}, TensorShape([]), tf.int32, None)}}, TensorShape([]), tf.int32, None)>\n"
     ]
    }
   ],
   "source": [
    "def node_batch_merge(graph):\n",
    "    graph = graph.merge_batch_to_components()\n",
    "    node_features = graph.node_sets['Label'].get_features_dict()\n",
    "    edge_features = graph.edge_sets['Correlation'].get_features_dict()\n",
    "    \n",
    "    label = node_features['index']\n",
    "    new_graph = graph.replace_features(\n",
    "        node_sets={'Label': node_features},\n",
    "        edge_sets={'Correlation': edge_features})\n",
    "    return new_graph, label\n",
    "\n",
    "def edge_batch_merge(graph):\n",
    "    graph = graph.merge_batch_to_components()\n",
    "    node_features = graph.node_sets['Label'].get_features_dict()\n",
    "    edge_features = graph.edge_sets['Correlation'].get_features_dict()\n",
    "    \n",
    "    new_graph = graph.replace_features(\n",
    "        node_sets={'Label': node_features},\n",
    "        edge_sets={'Correlation': edge_features})\n",
    "    return new_graph\n",
    "\n",
    "def create_dataset(graph,function):\n",
    "    dataset = tf.data.Dataset.from_tensors(graph)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset.map(function)\n",
    "\n",
    "train_node_dataset = create_dataset(train_tensor, node_batch_merge)\n",
    "train_edge_dataset = create_dataset(train_tensor, edge_batch_merge)\n",
    "\n",
    "print(train_node_dataset)\n",
    "print(train_edge_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6a7884f13482bfeff231b5fb49de16292961fb33d1c438236f0c066aa6f0670"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
